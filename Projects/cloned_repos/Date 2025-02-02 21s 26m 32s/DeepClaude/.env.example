# 客户端请求时允许通过请求的 API KEY，无需在当前环境变量当中手动添加 Bearer，目前只支持一个，未来可以升级为数组/toml/yaml 或专门的管理工具
ALLOW_API_KEY=your_api_key

# DeepSeek API KEY，默认为 DeepSeek 官方 API，只支持 r1 系列模型（包括基于 llama 和 qwen 的密集模型，1.5b、7b、8b、14b、32b、70b、671b）
# 除了采用官网的 DeepSeek r1 外，还推荐以下：
# 1.SiliconFlow 的 deepseek-ai/DeepSeek-R1 获取 API KEY 的链接：https://cloud.siliconflow.cn/i/RXikvHE2 (点击此链接可以获得到 2000 万免费 tokens)
# 2.Groq 托管的 deepseek-r1-distill-llama-70b 获取 API KEY 的链接：https://console.groq.com/docs/models
# 3.本地 Ollama 运行的 DeepSeek r1 , 可以根据自己电脑的内存和显存大小而定，推荐 7b、8b、14b 最佳，获取链接：https://ollama.com
DEEPSEEK_API_KEY=your_api_key
DEEPSEEK_API_URL=https://api.deepseek.com/v1/chat/completions
DEEPSEEK_MODEL=deepseek-reasoner


# Claude API KEY，默认为 Claude 官方 API，只推荐 Claude 3.5 Sonnet 模型，不推荐其他模型
CLAUDE_API_KEY=your_api_key
CLAUDE_MODEL=claude-3-5-sonnet-20241022